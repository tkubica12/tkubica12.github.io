---
layout: post
published: true
title: Deep dive do observability AI agentÅ¯ s Microsoft Agent Framework - metriky a logy, konverze na managed Prometheus a Grafana v Azure
tags:
- AI
- OpenTelemetry
- Monitoring
---
Tracing je pro AI agenty nejdÅ¯leÅ¾itÄ›jÅ¡Ã­ disciplÃ­nou, ale logy a metriky takÃ© majÃ­ svoje mÃ­sto. KlasickÃ© logy lze doruÄovat pÅ™es OpenTelemetry a koneÄnÄ› tak krÃ¡snÄ› sjednotit logovacÃ­ cesty pÅ™Ã­padnÄ› je korelovat s trasovÃ¡nÃ­m. No a metriky? HloubkovÃ© analÃ½zy, sloÅ¾itÃ© query a skvÄ›lÃ© moÅ¾nosti filtracÃ­ a agregacÃ­ v UI jsou fajn, ale Äasto uvÃ­tÃ¡te jednoduchou vizualizaci v GrafanÄ›. Å½Ã¡dnÃ© sloÅ¾itosti - klÃ­ÄovÃ© metriky pÅ™es zÃ¡kladnÃ­ dimenze. I to jste dnes schopni Å™eÅ¡it pÅ™es OpenTelemetry s kolektorem.

V prvnÃ­m dÃ­lu sÃ©rie jsme se zamÄ›Å™ili na sÃ©mantickÃ© konvence GenAI v OpenTelemetry a zÃ¡kladnÃ­ instrumentaci Microsoft Agent Frameworku vÄetnÄ› dÅ¯vodÅ¯ pouÅ¾itÃ­ kolektoru. Na to nynÃ­ navazujeme praktiÄtÄ›jÅ¡Ã­ ÄÃ¡stÃ­ o metrikÃ¡ch a logovÃ¡nÃ­.

# ProÄ Å™eÅ¡it metriky a ne jen trasovÃ¡nÃ­
Jak uÅ¾ jsem naznaÄoval trasovÃ¡nÃ­ a logovÃ¡nÃ­ jsou pomÄ›rnÄ› hutnÃ© disciplÃ­ny o to jak co do vyhodnocenÃ­ vÃ½sledkÅ¯, tak co do ceny cloudovÃ© sluÅ¾by nebo prostoru ve storage. Metriky jsou jednoduÅ¡Å¡Ã­ z nÄ›kolika pohledÅ¯. 

Backend pouÅ¾Ã­vÃ¡ typicky nÄ›jakou time-series databÃ¡zi a to je pÅ™Ã­pad jak slavnÃ©ho Promethea, tak tÅ™eba Mimir od Grafana nebo Azure Monitoru. Tyto databÃ¡ze jsou optimalizovanÃ© na ÄasovÃ© Å™ady s dimenzemi a jsou tak velmi rychlÃ© a ve finÃ¡le levnÃ©. Je to dÃ­ky tomu, Å¾e uloÅ¾enÃ­ jako log se budou Äasto opakovat metadata a databÃ¡ze bude Å™Ã¡dkovÄ› orientovanÃ¡ (optimalizovanÃ¡ na pÅ™idÃ¡vÃ¡nÃ­, filtrace, tedy operace pÅ™es Å™Ã¡dky). Metriky jsou uspoÅ™Ã¡danÃ© jinak a dokonce i hodnoty samotnÃ© se komprimujÃ­ napÅ™Ã­klad pÅ™es XOR - ÄasovÃ© Å™ady jsou si Äasto podobnÃ© (napÅ™. o nÄ›co rostou nebo oscilujÃ­ kolem nÄ›jakÃ© hodnoty), takÅ¾e velkÃ¡ bitovÃ¡ ÄÃ¡st odeÄtu (ÄÃ­sla) se opakuje a lze ji vynechat (Å™Ã­kÃ¡ se, Å¾e samotnÃ© metriky lze bÄ›Å¾nÄ› komprimovat 8x - a k tomu pÅ™idejme to efektivnÃ­ uloÅ¾enÃ­, kde se neopakujÃ­ metadata).

DotazovacÃ­ jazyky jsou podle mÄ› taky jednoduÅ¡Å¡Ã­. KdyÅ¾ srovnÃ¡m PromQL (zlatÃ½ standard, kterÃ½ umÃ­ jak samotnÃ½ Prometheus tak i Azure Monitor for Prometheus nebo Mimir) s jazyky pro logy Äi trasovÃ¡nÃ­ (KQL v Azure, QL u Elastic, SPL u Splunk, LogQL u Loki), metriky pochopÃ­m o dost rychleji. NavÃ­c v grafickÃ½ch nÃ¡strojÃ­ch si vÄ›tÅ¡inu vÄ›cÃ­ jednoduÅ¡e naklikÃ¡te (napÅ™Ã­klad Grafana dashboard), coÅ¾ u logovadel snadnÃ© nenÃ­ (tam snadno filtrujete, ale agregaÄnÃ­ dotazy jsou sloÅ¾itÄ›jÅ¡Ã­).

Ve finÃ¡le tedy Metriky chci!

Pro AI agenty se nejÄastÄ›ji osvÄ›dÄuje mÃ­t counter pro vstupnÃ­/vÃ½stupnÃ­ tokeny (odvozenÃ­ nÃ¡kladÅ¯ pÅ™es cenu na token v dashboardu), histogram pro latenci poÅ¾adavkÅ¯ kvÅ¯li p95/p99 tail analÃ½ze a counter pro chyby s dimenzÃ­ typu chyby. VyhÃ½bejte se uklÃ¡dÃ¡nÃ­ plnÃ½ch promptÅ¯ nebo volnÃ½ch textÅ¯ do metrik â€“ patÅ™Ã­ do trasovÃ¡nÃ­ nebo Å™Ã­zenÃ½ch logÅ¯ s anonymizacÃ­. Sledujte kardinalitu: model version, scÃ©nÃ¡Å™ a uÅ¾ivatelskÃ¡ role jsou vÄ›tÅ¡inou bezpeÄnÃ©, zatÃ­mco per-user Äi per-session metriky rychle rostou.

# Instrumentace
Microsoft Agent Framework emituje nejjednoduÅ¡Å¡Ã­ metriky v rÃ¡mci svÃ© instrumentace, takÅ¾e se na nÄ› staÄÃ­ jen koukat.

[![](/images/2025/2025-10-27-19-50-14.png){:class="img-fluid"}](/images/2025/2025-10-27-19-50-14.png)

Tady jsou zabudovanÃ© dimenze, podle kterÃ½ch lze snadno filtrovat a mÄ›nit vizualizaci. NapÅ™Ã­klad vstupnÃ­ a vÃ½stupnÃ­ tokeny, pouÅ¾itÃ½ LLM model, provider, endpoint.

[![](/images/2025/2025-10-27-19-50-48.png){:class="img-fluid"}](/images/2025/2025-10-27-19-50-48.png)

DobrÃ© ale je, Å¾e mohu pomÄ›rnÄ› snadno pÅ™idat svoje vlastnÃ­ metriky a jejich dimenze. Typicky to budou byznys metriky jako je poÄet zpracovanÃ½ch objednÃ¡vek a tak podobnÄ›. JÃ¡ jsem se rozhodl udÄ›lat si vlastnÃ­ metriku na poÄet tokenÅ¯. RozÅ¡Ã­Å™it ty stÃ¡vajÃ­cÃ­ se mi zdÃ¡lo hodnÄ› komplikovanÃ© (na rozdÃ­l od moÅ¾nosti pÅ™idat atributy do trasovÃ¡nÃ­), tak jsem si udÄ›lal svoje a pÅ™idal k nim dalÅ¡Ã­ dimenze.

```python
metric_resource = Resource(attributes={
    SERVICE_NAME: os.getenv("OTEL_SERVICE_NAME", "agent")
})
metric_reader = PeriodicExportingMetricReader(
    OTLPMetricExporter(endpoint=otlp_endpoint, insecure=True),
    export_interval_millis=5000,  # Export every 5 seconds for testing
)
meter_provider = MeterProvider(resource=metric_resource, metric_readers=[metric_reader])
otel_metrics.set_meter_provider(meter_provider)

is_vip = "vip" in user_context.get("user.roles", [])
self.agent_call_counter.add(
    demo_value,
    attributes={
        "service.name": os.getenv("OTEL_SERVICE_NAME", "agent"),
        "user.id": user_context.get("user.id", "unknown"),
        "user.is_vip": str(is_vip).lower(),
        "organization.department": user_context.get("organization.department", "unknown"),
        "session.id": user_context.get("session.id", "unknown"),
        "scenario_id": "local-maf-multiagent",
        "scenario_type": "multi-agent",
        "orchestration": "magentic",
    }
)
print(f"ğŸ“Š Custom metric recorded: custom_agent_call_count={demo_value}")
```

[![](/images/2025/2025-10-27-19-51-42.png){:class="img-fluid"}](/images/2025/2025-10-27-19-51-42.png)

VidÃ­me tam i moje pÅ™idanÃ© dimenze, podle kterÃ½ch lze snadno filtrovat a vizualizovat.

PoznÃ¡mka ke kardinalitÄ›: dimenze jako `user.id` a `session.id` jsou vysoce kardinalitnÃ­ a u metrik mohou vÃ½raznÄ› zvÃ½Å¡it nÃ¡klady i zÃ¡tÄ›Å¾ backendu â€“ u metrik proto radÄ›ji agregujte na ÃºroveÅˆ rolÃ­, scÃ©nÃ¡Å™e nebo VIP flagu; v trasovÃ¡nÃ­ si tyto identifikÃ¡tory ponechejte, protoÅ¾e tam jsou pro analÃ½zu a korelaci uÅ¾iteÄnÃ©.

[![](/images/2025/2025-10-27-19-52-36.png){:class="img-fluid"}](/images/2025/2025-10-27-19-52-36.png)


# Jak nastavit OpenTelemetry metriky do Azure managed sluÅ¾eb
V pÅ™edchozÃ­m odstavci jsme pouÅ¾Ã­vali Aspire Dashboard a ten pÅ™Ã­mo podporuje metriky. VÄ›tÅ¡ina z vÃ¡s ale asi bude spÃ­Å¡e znÃ¡t Prometheus. Pod nÃ­m se skrÃ½vajÃ­ tÅ™i vÄ›ci - SDK pro aplikace a mechanismus vystavovÃ¡nÃ­ metrik (v podstatÄ› pÅ™es webovou strÃ¡nku, kam dÃ¡ aplikace svÃ© metriky k odeÄtu), databÃ¡ze pro uloÅ¾enÃ­ metrik a dotazovacÃ­ jazyk PromQL. V naÅ¡em pÅ™Ã­padÄ› odstranÃ­me Prometheus SDK - nebudeme pouÅ¾Ã­vat, chceme jÃ­t cestou OpenTelemetry a push. Z druhÃ© strany si urÄitÄ› chceme ponechat PromQL, protoÅ¾e ten je velmi pouÅ¾Ã­vanÃ½ a pÅ™Ã­jemnÃ½. OpenTelemetry kolektor dokÃ¡Å¾e vzÃ­t OTEL metriky a poslat je dÃ¡l ve formÃ¡tu Prometheus pouÅ¾itÃ­m tzv. remote-write. V mÃ©m pÅ™Ã­padÄ› to ale nebude skuteÄnÃ½ Prometheus, ale s nÃ­m kompatibilnÃ­ jinÃ¡ technologie. Tak jak Grafana Mimir dokÃ¡Å¾e nahradit Prometheus a pÅ™itom bÃ½t plnÄ› kompatibilnÃ­, tak Azure Monitor for Prometheus dÄ›lÃ¡ nÄ›co podobnÃ©ho.

BohuÅ¾el Azure Monitor for Prometheus vyÅ¾aduje pÅ™Ã­snÃ© enterprise zabezpeÄenÃ­ a to se Å¡patnÄ› nastavuje pÅ™Ã­mo v kontejneru kolektoru, ale dÃ¡ se to vyÅ™eÅ¡it sidecar - v tÃ© bÄ›Å¾Ã­ Prometheus bez zabezpeÄenÃ­, kolektor to do nÄ›j posÃ­lÃ¡ pÅ™es remote-write a sidecar pak mÃ¡ autentizaci pÅ™es Managed Identity a remote-write do Azure Monitoru. PopsÃ¡no je to v [dokumentaci](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-remote-write-managed-identity)

Kolektor pak vypadÃ¡ nÄ›jak takhle:

```yaml
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

    processors:
      batch:
        timeout: 5s
        send_batch_size: 1024
      memory_limiter:
        check_interval: 1s
        limit_mib: 512

    exporters:
      # Prometheus Remote Write exporter for Azure Monitor Prometheus
      # Uses sidecar container for Azure AD token management
      # The sidecar listens on localhost:8081 and injects the Authorization header
      prometheusremotewrite:
        endpoint: "http://localhost:8081/api/v1/write"
        tls:
          insecure: true
        resource_to_telemetry_conversion:
          enabled: true

    service:
      pipelines:
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [prometheusremotewrite]
```

NÃ¡slednÄ› mÃ¡m nad tÃ­m Azure Managed Grafana a uÅ¾ se lze pustit do tvorby dashboardÅ¯.

[![](/images/2025/2025-10-28-11-11-28.png){:class="img-fluid"}](/images/2025/2025-10-28-11-11-28.png)


# LogovÃ¡nÃ­ pÅ™es OpenTelemetry
KlasickÃ½ zpÅ¯sob logovÃ¡nÃ­ je buÄ sbÄ›r obrazovky (stdout) nebo nÃ¡stroje jako je Logstash, Fluentd nebo nativnÃ­ nÃ¡stroje konkrÃ©tnÃ­ho Å™eÅ¡enÃ­ jako je Graylog nebo Loki. OpenTelemetry ale pÅ™inÃ¡Å¡Ã­ sjednocenÃ­ a standardizaci, takÅ¾e jednotnÃ© otevÅ™enÃ© SDK mÅ¯Å¾ete pouÅ¾Ã­t na trasovÃ¡nÃ­, metriky i logy. BohuÅ¾el v dobÄ› psanÃ­ tohoto ÄlÃ¡nku Azure Monitor jeÅ¡tÄ› logy pÅ™es OpenTelemetry nepodporuje (ale prÃ½ se na tom pracuje), protoÅ¾e pod kapotou je Kusto ingestion pipeline a jejÃ­ enterprise nadstavby (napÅ™. RBAC podle zdroje) a nenÃ­ to triviÃ¡lnÃ­ pÅ™edÄ›lat. NicmÃ©nÄ› pro ÃºÄely mÃ©ho zkoumÃ¡nÃ­ observability AI agentÅ¯ jsem OpenTelemetry pouÅ¾il v kombinaci s Aspire Dashboard pro rychlÃ½ nÃ¡hled.

```python
# Configure OTLP logging
from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler
from opentelemetry.sdk._logs.export import BatchLogRecordProcessor
from opentelemetry.exporter.otlp.proto.grpc._log_exporter import OTLPLogExporter
from opentelemetry.sdk.resources import Resource, SERVICE_NAME
from opentelemetry._logs import set_logger_provider

# Create log provider with resource
log_resource = Resource(attributes={
    SERVICE_NAME: os.getenv("OTEL_SERVICE_NAME", "agent")
})
logger_provider = LoggerProvider(resource=log_resource)
set_logger_provider(logger_provider)

# Add OTLP log exporter
otlp_log_exporter = OTLPLogExporter(endpoint=otlp_endpoint, insecure=True)
logger_provider.add_log_record_processor(BatchLogRecordProcessor(otlp_log_exporter))

# Attach OTLP handler to root logger for telemetry collection
otlp_handler = LoggingHandler(level=logging.INFO, logger_provider=logger_provider)

# Configure root logger: NO console handlers, only OTLP
root_logger = logging.getLogger()
root_logger.handlers.clear()  # Remove all console handlers
root_logger.addHandler(otlp_handler)  # Only OTLP handler
root_logger.setLevel(logging.INFO)

# Also configure our app logger
logger.addHandler(otlp_handler)
```

Takhle to vypadÃ¡ v dashboardu.

[![](/images/2025/2025-10-28-11-01-54.png){:class="img-fluid"}](/images/2025/2025-10-28-11-01-54.png)

[![](/images/2025/2025-10-28-11-02-23.png){:class="img-fluid"}](/images/2025/2025-10-28-11-02-23.png)


Dnes jsme se zamÄ›Å™ili na metriky a logy a pÅ™Ã­Å¡tÄ› se mÅ¯Å¾eme vrhnout do naÅ¡eho hlavnÃ­ho tÃ©matu, do toho, co je pro observabilitu AI agentÅ¯ nejdÅ¯leÅ¾itÄ›jÅ¡Ã­ - trasovÃ¡nÃ­. ZaÄneme s open source nÃ¡stroji Aspire Dashboard a LangFuse, pak pÅ™idÃ¡me Azure AI Foundry a App Insights.