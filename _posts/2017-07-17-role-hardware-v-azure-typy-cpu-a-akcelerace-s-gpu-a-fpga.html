---
layout: post
status: publish
published: true
title: Role hardware v Azure - typy CPU a akcelerace s GPU a FPGA
author:
  display_name: Tomáš Kubica
  login: tomas
  email: tkubica@centrum.cz
  url: ''
author_login: tomas
author_email: tkubica@centrum.cz
wordpress_id: 771
wordpress_url: http://tomaskubica.cz/?p=771
date: '2017-07-17 13:39:55 +0000'
date_gmt: '2017-07-17 12:39:55 +0000'
categories:
tags:
- Compute
---
<p>Pokud se zaměříme na infrastrukturní služby a platformní vlastnosti necháme pro tento článek stranou, může se z pohledu běžné byznysové aplikace cloud jevit jako jednolitý a hardwarově univerzální svět. A to je dobře. Má to být jednoduché, za malý stroj malé peníze, za velký stroj velké peníze a patřičný výkon ve všech směrech - počet jader, paměť, síťová propustnost. Ne všechno je ale web server nebo databáze. Existují výpočetně nebo datově náročné úlohy a univerzální hardware není optimální řešení. To je ten okamžik, kdy vám Azure může odhalit speciality pro náročné - vysokofrekvenční procesory, různé varianty GPU a také FPGA. Proč někdy na hardware záleží a proč je na tom Azure dobře?<!--more--></p>
<h1>CPU vs. GPU vs. FPGA vs. ASIC</h1>
<p>Na jedné straně škály stojí CPU. Univerzální hardware, který může aplikacím nabídnout velmi komplexní instrukční sadu a dokáže v zásadě úplně cokoli. Nic ale není zadarmo. Univerzálnost znamená nízkou efektivitu, protože uděláte obrovské množství operací (= latence, spotřeba, nižší výkon) pro implementaci něčeho, co by se třeba dalo udělat jako hardwarová logika. Na druhou stranu CPU zvládne i tak komplexní úlohy, že implementace takové logiky přímo do hardware by byla nad praktické lidské síly. Představte si CPU jako švýcarský nůž. Vyřešíte s ním každou situaci, ale trvá, než najdete co potřebujete a je to takové titěrné, nedá se do toho pořádně opřít a tak se víc nadřete a trvá to déle.</p>
<p>Podívejme se teď na druhou stranu spektra, na ASIC. Jde o integrovaný obvod jehož aplikační logika je přímo vypálena do čipu. CPU potřebuje instrukčně tancovat kolem dat, takže si je musí nahrát do sebe (do registrů) a pracovat kolem nich. ASIC je spíše průtokový, vstupní data jím protahujete a oni se po cestě různě modifikují až se z nich stane výstup. Díky své specifičnosti dosahuje jednoznačně největších výkonů (vzhledem ke spotřebě a ceně výroby), mluvíme i o několikařádových rozdílech. Samozřejmě jsou tady ovšem obrovské náklady na design a testování. ASIC je oblíbený tam, kde aplikační logika je relativně jednoduchá a statická a požadavky na výkon extrémní - například v síťových přepínačích (ale ve směrovačích či firewallech ne, tam je rigidnost ASICů problém). Sebemenší změna znamená čip vyhodit a navrhnut nový. Jejich vývoj je náročný a zdlouhavý, pokud tam máte bug, je tam vypálen na celou vaší roční plánovanou výrobu. ASIC není švýcarský nůž, ale naopak konkrétní klíč určité velikosti a typu. Svou práci vykoná podstatně lépe, efektivněji a vyjde levněji. Jakmile ale místo "šestky" potřebujete "osmičku", nemáte šanci.</p>
<p>GPU a FPGA jsou mezi těmito dvěma póly. GPU je ve svém fungování podobné CPU (nasaje data a nad nima počítá), ale zaměřuje se na podporu menšího množství jednodušších operací a nižší taktování (kolem 1 GHz). Díky tomu se takových jader na čip vejdou stovky či tisíce. To je ideální pro vysoce paralalezované výpočty, klasicky zejména grafika, ale dnes celá řada dalších (risk analýza, trénování machine learning systémů, šifrování). Za rámcově podobnou cenu tak místo univerzálního CPU s třeba 16 jádry získáte soustavu jednoduchých procesorů, ale v počtu třeba 1000 jader. Pro některé situace je to dramaticky výhodnější.</p>
<p>A co FPGA? To je technologie, která se mi vždycky líbila. Jak název popisuje jedná se o hradlové pole (soustava velkého množství primitivních jednotek), které ovšem můžete programovatelným způsobem propojit. Historicky byla problémem FPGA nízká kapacita a složité programování. Vy si totiž defacto poskládáte svůj obvod, ASIC. Jen místo vypálení spojů (aplikační logiky) v továrně to uděláte až po výrobě softwarově, jenže jste museli používat nástroje z mikročipového světa, což není zrovna "programování" tak, jak developer zná. Nicméně to se změnilo a existuje hned několik rámců, jak s FPGA pracovat pohodlně. Samozřejmě oproti ASIC něco ztratíte, ale stále platí, že vaše aplikační logika se provádí přímo v hardware - průtokově. Data natečou jak řeka do peřejí a kameny je omelou tak, že na konci vypadne výsledek. Je to flexibilnější než ASIC a přitom hardwarově silné. Představě co FPGA je možná napomůže říct, že jste schopni v FPGA postavit CPU (nějaké jednodušší typu ARM ... nicméně to samozřejmě nikdo nedělá, nedává to smysl). Jednoduché paralelní úlohy s potřebou extrémního výkonu a nízké latence, ale přitom programovatelnosti, takže potřebuje-li změnu nemusíte předělat výrobní linku? Tam se FPGA hodí. Neuronové sítě a machine learning obecně, networking operace, zpracování streaming dat, obrazu nebo processing signálu (DSP).</p>
<h1>CPU v Azure</h1>
<p>Třídy a generace VM obvykle disponují i jiným procesorem. U některých se jeho identita uvádí, u některých ne. V zásadě nejslabší CPU je v mašinách typu A a Av2 (procesor není uváděn, ale na webu je dostupný index výkonnosti - ten ukazuje, že A je zruba na polovině výkonu Dv2 jádra). Tato řada v zásadě umožňuje jistou normalizaci, tedy výkon je sice konzistentní, ale může vzniknout normalizací různých typů procesorů. Klasické byznys VM jako Dv2 je postaveno na Intel E5-2673 v3  (2,4 GHz s 3,1 GHz Turbo) a stejný procesor najdete v řadě F (má méně paměti na jádro, takže se používá pro výpočetně orientované situace). Pro nejnáročnější (zejména špatně paralelizovatelné) výpočty, kde potřebujete vysokou frekvenci spíše než hodně jader, nabízí Azure řadu H postavenou na E5-2667 v3 (3,2 GHz s 3,6 GHz Turbo). Index výkonu je u této řady asi o 50% nad řadou Dv2. Zmíněné řady jsou postaveny tak, že Hyper-Threading je vypnutý, tedy získáváte fyzická jádra.</p>
<p>Nejnovější generace typů strojů už využívá Hyper-Threading (2 virtuální jádra na jedno fyzické), díky čemuž můžete získat větší počet jader pro běh náročných aplikací. Do této kategorie patří nové Dv3 (klasická VM), Ev3 (VM s větším množstvím paměti), M (mamutí velikosti paměti až 3,5TB) i řada L (masivní lokální SSD pro NoSQL). D/E v3 je evolučním krokem z v2 a tomu odpovídá i CPU. To je totiž stejného typu, jen nové generace, čili  E5-2673 v4 (2,3 GHz s 3,6 GHz Turbo). Nové CPU přineslo nové počty core a s tím i nové (větší) typy VM - nejvyšší D64 v3 nabízí 64 core.</p>
<p>Co se týče zmíněné M-series, tak ta je zaměřena na masivní potřeby jaké má třeba SAP HANA. Nejvyšší model má 3,5TB a 128 jader. Trocha počítání vás jistě přivede k tomu, že i při Hyper-Threadingu na to nemůžou dva sokety běžného CPU stačit. Přesně tak. Tato high-end mašina využívá E7-8890 v3, tedy procesoru, který dokáže vytvářet víc než 2-socketové systémy. Přesný hardwarový setup se neuvádí, ale při troše počítání a znalosti tvorby systémů je zřejmé, že tento 18-core (36 multi-threaded) procesor bude v Azure v 4-socketovém systému. To vám dává 144 jader, tedy dost jak pro hostitele (virtualizace, control plane apod.) tak pro zmíněnou nejvyšší 128-core VM.</p>
<p>Mimochodem je tu ještě jedna specialita - systémy pro brutální SAP instalace, kde nezbývá, než použít (trochu ne-cloudově) fyzické železo. Nejvyšší stroj S960m vám dá hned 20x E7-8890 v4, tedy neuvěřitelných 960 HT jader a 20TB RAM.</p>
<h1>GPU v Azure</h1>
<p>Azure nabízí dva typy NVIDIA karet a byly oznámeny další dva. Nejde o žádné virtualizované GPU - Azure pod kapotovou využívá technologii DDA ve Windows Server 2016, která umožní do Azure VM přímo namapovat konkrétní PCI-E zařízení. Máte tedy přímý přístup ke grafické kartě. Jaké jsou tedy možnosti?</p>
<p>Levnější variantou zaměřenou na výpočty je řada mašin NC, které nabízí jeden až čtyři jádra grafické karty NVIDIA Tesla K80 (tzn. čip GK210). Je to karta relativně "starší" (2015), ale z vyšší kategorie. Nabízí akceleraci jak single tak double precision, takže na výpočetní operace s využitím CUDA instrukcí je perfektní. Rendering, matematické výpočty, monte carlo simulace, machine learning či chroupání genomu jsou ideální aplikace pro NC stroje.</p>
<p>Druhou variantou jsou stroje typu NV, tedy grafické řešení zaměřené na vizualizaci, tedy práci v reálném čase. Zatímco NC bude na pozadí zuřivě počítat, u NV se připojí člověk (architekt, designér apod.) a v reálném čase bude pracovat s modelem. NV je tedy možné použít jako grafickou stanici a to je také důvod, proč je v ceně stroje licence GRID 2.0 (Quadro). NV řada je postavena na kartě Tesla M60 (čip GM204) vydané ke konci roku 2015 a dosahuje výborných hodnot v single precision.</p>
<p>Microsoft oznámil příchod dalších dvou typů GPU strojů v blízké budoucnosti. Ten první přichází s nejnovější generací NVIDIA architektury a je zaměřen na single precision operace. Díky tomu se dobře hodí zejména do oblastí jako je machine learning. Nová řada VM bude mít označení ND a pod kapotou bude čip NVIDIA P40 vydaný ke konci roku 2016. V single precision operacích dává dvojnásobek výkonu K80 v aktuální NC řadě.</p>
<p>Druhým oznameným modelem je řešení zaměřené na univerzální výpočty a to včetně double precision, je tedy přímým pokračovatelem K80 - jde o model NVIDIA P100. Z toho důvodu půjde o VM označenou jako NC v2 a nabízí dvojnásobný výkon ve všech směrech.</p>
<h1>FPGA v Azure</h1>
<p>Řekněme si jen to, co je veřejnou informací. Microsoft začal dávat FPGA do serverů už v roce 2015, byť v ten okamžik k tomu neměl žádné konkrétní využití. Vychází to ze zkušeností, které firma posbírala z jiných projektů v oblastech indexování či machine learningu. Zkrátka bylo zřejmé, že to může jednou dávat obrovský smysl. FPGA se do serverů namontovalo zajímavým způsobem - jsou jednak vysokorychlostně propojeny s CPU (tzn. to může potenciálně FPGA využít pro akceleraci některých výpočtů) ale současně na síť (tedy pakety mohou procházet skrz FPGA). To bylo prozíravé a dnes už přináší první konkrétní technologii dostupnou zákazníkům a podle všeho jsou s tím další a dost velké plány.</p>
<p>Díky tomu, že FPGA sedí v síťovém subsystému je možné do něj zakomponovat síťové operace. V sítích jsou často věci řešeny v ASIC - jak v přepínačích, tak na síťových kartách. Tam je ale vše "vypáleno" (jak už v tomto článku padlo). Azure je postaven na rozsáhlé softwarově definované síťařině a potřeby takto velkého cloudu jsou jiné, než v běžném enterprise. Soustava funkcí v ASIC tedy nestačí potřebám. Co se podařilo je přenést implementaci Azure SDN právě do FPGA. Místo tradičních virtuálních switchů pod kapotou (kde se manipuluje s pakety, dělají tunely, překlady apod.) můžete přesunout toto zpracování do FPGA. Tomu se říká Azure Accelerated Networking. Je dostupné pro vyjmenované vyšší typy VM a vyžaduje jiný driver (nejedete na principu simulace třeba e1000 karty, ale budete mít přímé drivery do Melanox karty - a odtamtud to jde na pozadí do FPGA). Místo virtuální karty a vSwitche tedy použijete SR-IOV pro přímý přístup na rozhraní karty a ta spolupracuje s FPGA na implementaci SDN logiky. Výsledek? Dvojice D15 VM dokáže mezi sebou komunikovat na reálné rychlosti 25 Gbps!</p>
<p>Co čekat dál? To není oznámeno, ale vezměte v úvahu, že FPGA je napojeno na síť, ale i přímo do CPU ... tak se nechme překvapit.</p>
<p>&nbsp;</p>
<p><em>Cloud vám umožňuje jednotným způsobem přistupovat ke zdrojům, to ale neznamená, že je všechno jednolité. Pro různé situace můžete potřebovat různý hardware a to vám Azure umožňuje. Navíc si můžete klidně jen na pár hodin půjčit stroje, které u sebe nemáte a nemá cenu je trvale vlastnit: high-end CPU s InfiniBand propojením, velmi výkonná vzdálená grafická pracovní stanice nebo šelmostroj s několika tisícovkami GPU jader na složité výpočty.</em></p>
