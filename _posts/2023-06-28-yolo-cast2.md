---
layout: post
published: true
title: "Je open source poÄÃ­taÄovÃ© vidÄ›nÃ­ typu YOLO dost dobrÃ©? A jak ho rozjet v Azure? ÄŒÃ¡st 2: finetuning vlastnÃ­mi obrÃ¡zky"
tags:
- AI
---
Do sluÅ¾by Azure Machine Learning jsem si pÅ™idal compute s NVIDIA A100 kartiÄkou, coÅ¾ je celkem dÄ›lo a pustil se do trÃ©novÃ¡nÃ­ YOLOv8. JakÃ© mÃ¡te moÅ¾nosti pÅ™idat svoje data, kudy do toho a jak to funguje? Tyhle hrÃ¡tky by nÃ¡m zase znovu mÄ›ly pomoci pochopit rÃ¡mcovÄ› co se dÄ›je pÅ™i trÃ©novÃ¡nÃ­ a k Äemu je transfer learning.

Budu si hrÃ¡t se svojÃ­ oblÃ­benou sadou, kterÃ¡ je nesmÃ­rnÄ› primitivnÃ­ - dva plyÅ¡Ã¡ci, 23 fotek na trÃ©novÃ¡nÃ­, 3 na validaci, 2 na test. To je samozÅ™ejmÄ› straÅ¡nÄ› mÃ¡lo a mÄ›li byste mÃ­t vÅ¾dy daleko vÃ­c, ale pro zÃ¡kladnÃ­ pÅ™edstavu tohle staÄÃ­ (ostatnÄ› uÅ¾ tyhle fotky pouÅ¾Ã­vÃ¡m asi Å¡est let na rychlÃ© vyzkouÅ¡enÃ­). TÄ›ch pÃ¡r let co uplynulo od poÅ™Ã­zenÃ­ tÄ›ch fotek dramaticky snÃ­Å¾ilo jejich oblÃ­benost dÃ­ky nÃ¡stupu puberty jejich majitele, tak snad majÃ­ radost, Å¾e jejich machine learning hodnota zÅ¯stala zatÃ­m zachovÃ¡na.

Jako obvykle data najdete na mÃ©m GitHubu a dnes se budeme pohybovat v [tomhle notebooku](https://github.com/tkubica12/ai-demos/blob/main/yolo/finetuning.ipynb)
YOLO formÃ¡t pro popis obdelnÃ­kÅ¯ pro objekty pouÅ¾Ã­vÃ¡ txt soubor ke kaÅ¾dÃ©mu obrÃ¡zkovÃ©mu souboru a v nÄ›m jednoduÅ¡e ID objektu a ÄtyÅ™i souÅ™adnicovÃ¡ ÄÃ­sla (resp dvÄ› souÅ™adnice stÅ™edu + Å¡Ã­Å™ka a dÃ©lka rÃ¡meÄku) - co objekt to Å™Ã¡dek. Pokud jste oznaÄovÃ¡nÃ­ objektÅ¯ udÄ›lali jako projekt v Azure, tak to podporuje vÃ½stup jen v COCO formÃ¡tu, takÅ¾e pak musÃ­te pÅ™evÃ¡dÄ›t (nebo pouÅ¾ijte CVAT, Label Studio nebo tÅ™eba Roboflow). ZkrÃ¡tka AML labelovÃ¡nÃ­ je ideÃ¡lnÃ­, pokud data budete dÃ¡l zpracovÃ¡vat v AML, protoÅ¾e vyplivne rovnou MLtable formÃ¡t, kterÃ½ je vstupem tÅ™eba do AutoML. NicmÃ©nÄ› to zatÃ­m nemÃ¡ yolov8 (jen yolov5), ale i kdyÅ¾ bude mÃ­t, tak zatÃ­m chci zÅ¯stat v notebooku, abychom si to osahali.

SamozÅ™ejmÄ› - tohle je straÅ¡nÄ› mÃ¡lo, dÄ›lat validaci na tÅ™ech fotkÃ¡ch je samozÅ™ejmÄ› mimo ... nicmÃ©nÄ› principy nÃ¡m odhalÃ­ i to.

# Transfer learning - vlastnÃ­ obrÃ¡zky, rychlÃ© a dobrÃ© vÃ½sledky
Moje Ãºloha mÃ¡ docela blÃ­zko ke generickÃ½m objektÅ¯m tak jak jsou tÅ™eba v COCO sadÄ›, kterÃ¡ byla pouÅ¾ita pro natrÃ©novÃ¡nÃ­ YOLOv8. CelÃ¡ finta je, Å¾e si do modelu naÄtu pÅ™edtrÃ©novanÃ½ yolo model, napÅ™Ã­klad ve variantÄ› object detection velikosti nano - stejnÄ› jako jsme to dÄ›lali minule. Tedy topologii, vypoÄÃ­tanÃ© vÃ¡hy, vÅ¡echno.

```python
model = YOLO('yolov8n.pt')
```

Minule jsme mu pÅ™edali obrÃ¡zek a uÅ¾ to frÄelo. TeÄ ale udÄ›lÃ¡me nÄ›co jinÃ©ho - pÅ™ipravÃ­me si data (popÃ­Å¡eme jejich strukturu v YAMLu) a rozjedeme trÃ©novÃ¡nÃ­. Borci model natrÃ©novali na velkÃ©m mnoÅ¾stvÃ­ dat a vÃ½sledkem toho vÅ¡eho jsou vlastnÄ› jen vÃ¡hy, tedy hodnoty, kterÃ© dosadÃ­me za neznÃ¡mÃ© do vzorcÅ¯. My teÄ tyhle hodnoty (vÃ¡hy) vezmeme a na naÅ¡ich datech je budeme brÃ¡t jako vÃ½chozÃ­ a budeme ladit dÃ¡l. NÄ›jakÃ© dvÄ› stovky vrstev a mraky parametrÅ¯ uÅ¾ umÃ­ rozpoznÃ¡vat tvary, pÅ™echody, hrany, textury, ale i ouÅ¡ka, nosy a nepotÅ™ebujeme prvnÃ­ vrstvy moc mÄ›nit (rozpoznÃ¡vajÃ­ typicky hodnÄ› nÃ­zkoÃºrovÅˆovÃ© vÄ›ci typu hrany), ale ty pozdÄ›jÅ¡Ã­ uÅ¾ trochu ano a zejmÃ©na na konci ty klasifikaÄnÃ­ vrstvy zcela (to, kde se z detekovanÃ½ch vlastnostÃ­ urÄÃ­ jakÃ¡ je to kategorie odstÅ™ihneme a dodÃ¡me svoje tÅ™Ã­dy a vrstvy). YOLOv8 to udÄ›lÃ¡, staÄÃ­ zapnout trÃ©nink.

```python
train = model.train(data='./datasets/2plysaci.yaml', epochs=100, imgsz=1024)
```

## MalÃ½ model
Vzal jsem tedy nejmenÅ¡Ã­ model a rozjel 100 epoch. Z grafÅ¯ se zdÃ¡lo, Å¾e model se jeÅ¡tÄ› chvilku zlepÅ¡oval, ale vÃ½sledky na test sadÄ› nebyly dobrÃ©, takÅ¾e 100 epoch evidentnÄ› na mÅ¯j scÃ©nÃ¡Å™ staÄilo. VidÃ­m, Å¾e moje A100 se moc nezapotila a do dvou minut to mÄ›la zmÃ¡knutÃ©. 

```
100 epochs completed in 0.028 hours.
Optimizer stripped from runs/detect/train13/weights/last.pt, 6.3MB
Optimizer stripped from runs/detect/train13/weights/best.pt, 6.3MB

Validating runs/detect/train13/weights/best.pt...
Ultralytics YOLOv8.0.120 ğŸš€ Python-3.8.5 torch-1.12.0 CUDA:0 (NVIDIA A100 80GB PCIe, 80995MiB)
Model summary (fused): 168 layers, 3006038 parameters, 0 gradients
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 44.20it/s]
                   all          3          6      0.987          1      0.995      0.888
                 oslik          3          3      0.986          1      0.995      0.929
                ovecka          3          3      0.988          1      0.995      0.847
Speed: 0.1ms preprocess, 2.7ms inference, 0.0ms loss, 0.9ms postprocess per image
```

MÃ¡me tady model s 3M parametry a vÅ¡imnÄ›te si, Å¾e soubor s jeho vÃ½sledky mÃ¡ asi 6MB (samozÅ™ejmÄ› stejnÄ› jako pÅ¯vodnÃ­ model -> k Å¾Ã¡dnÃ© vÃ½znamnÃ© zmÄ›nÄ› velikosti nedoÅ¡lo, jen jsme trochu jinak udÄ›lali vÃ¡hy a tak). Na testovacÃ­ fotce to vyÅ¡lo opravdu pÄ›knÄ›.

[![](/images/2023/2023-06-20-15-36-57.png){:class="img-fluid"}](/images/2023/2023-06-20-15-36-57.png)

KdyÅ¾ koukneme na metriky, tak je vidÄ›t, Å¾e model se krÃ¡snÄ› uÄil a mAP50-95 se vyÅ¡plhalo pÅ™Ã­jemnÄ› vysoko (jak jsem psal - validaÄnÃ­ i trÃ©novacÃ­ sada je smÄ›Å¡nÄ› malÃ¡, takÅ¾e to trochu lÃ­tÃ¡, ale trend tam je).

[![](/images/2023/2023-06-20-15-37-33.png){:class="img-fluid"}](/images/2023/2023-06-20-15-37-33.png)

Pro jistotu si jeÅ¡tÄ› ukÃ¡Å¾eme nÄ›jakÃ½ jinÃ½ obrÃ¡zek. OÄekÃ¡vÃ¡me, Å¾e na nÄ›m neuvidÃ­ model oslÃ­ka nebo oveÄku, ale taky bohuÅ¾el nepoznÃ¡ ÄlovÄ›ka (klasifikaci pÅ¯vodnÃ­ho modelu jsme nahradili plyÅ¡Ã¡ky). 

[![](/images/2023/2023-06-20-15-48-17.png){:class="img-fluid"}](/images/2023/2023-06-20-15-48-17.png)

# VÄ›tÅ¡Ã­ modely a problÃ©m overfittingu
SkvÄ›lÃ©. A100 mÃ¡m naÅ¾havenou, dÃ¡me vÄ›tÅ¡Ã­ model s 11M parametry. JenÅ¾e moje mnoÅ¾stvÃ­ dat je opravdu smÄ›Å¡nÄ› malÃ© a nezdÃ¡ se, Å¾e by nano model nebyl dostateÄnÄ› komplexnÃ­ na to, aby moje plyÅ¡Ã¡ky pochopil. Nejen, Å¾e moÅ¾nÃ¡ zaplatÃ­m zbyteÄnÄ›, ale vÄ›tÅ¡Ã­ model bude mÃ­t tendenci se pÅ™etrÃ©novat a vidÄ›t pak oslÃ­ky ÃºplnÄ› ve vÅ¡em.

```
100 epochs completed in 0.093 hours.
Optimizer stripped from runs/detect/train12/weights/last.pt, 22.6MB
Optimizer stripped from runs/detect/train12/weights/best.pt, 22.6MB

Validating runs/detect/train12/weights/best.pt...
Ultralytics YOLOv8.0.120 ğŸš€ Python-3.8.5 torch-1.12.0 CUDA:0 (NVIDIA A100 80GB PCIe, 80995MiB)
Model summary (fused): 168 layers, 11126358 parameters, 0 gradients
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 45.54it/s]
                   all          3          6      0.973          1      0.995      0.941
                 oslik          3          3      0.992          1      0.995       0.93
                ovecka          3          3      0.954          1      0.995      0.952
Speed: 0.2ms preprocess, 2.6ms inference, 0.0ms loss, 0.6ms postprocess per image
```

Za nÄ›jakÃ½ch 6 minut to je hotovÃ© a vÃ½sledky, asi dle oÄekÃ¡vÃ¡nÃ­, nejsou nÄ›jak lepÅ¡Ã­.

[![](/images/2023/2023-06-20-15-32-01.png){:class="img-fluid"}](/images/2023/2023-06-20-15-32-01.png)

VÃ½sledek v poÅ™Ã¡dku, byÅ¥ s niÅ¾Å¡Ã­ jistotou.

[![](/images/2023/2023-06-20-15-28-23.png){:class="img-fluid"}](/images/2023/2023-06-20-15-28-23.png)

Pro zajÃ­mavost pojÄme pÅ™itoÄit - dejme model s 43M parametry. 

```
57 epochs completed in 0.072 hours.
Optimizer stripped from runs/detect/train11/weights/last.pt, 87.7MB
Optimizer stripped from runs/detect/train11/weights/best.pt, 87.7MB

Validating runs/detect/train11/weights/best.pt...
Ultralytics YOLOv8.0.120 ğŸš€ Python-3.8.5 torch-1.12.0 CUDA:0 (NVIDIA A100 80GB PCIe, 80995MiB)
Model summary (fused): 268 layers, 43608150 parameters, 0 gradients
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.79it/s]
                   all          3          6        0.5      0.833      0.602      0.475
                 oslik          3          3        0.5      0.667      0.474      0.319
                ovecka          3          3        0.5          1      0.731      0.632
Speed: 0.1ms preprocess, 5.6ms inference, 0.0ms loss, 7.5ms postprocess per image
```

Model zastavil dÅ™Ã­v (po 50 epoch po sobÄ› se nezlepÅ¡il), po pÅ™epoÄtu na 100 epoch by to trvalo nÄ›jakÃ½ch 8 minut (A100 se koneÄnÄ› trochu procviÄÃ­). Dejme testovacÃ­ obrÃ¡zek a safra - nÄ›kdo nÃ¡m to tady s uÄenÃ­m pÅ™ehnal.

[![](/images/2023/2023-06-20-15-17-25.png){:class="img-fluid"}](/images/2023/2023-06-20-15-17-25.png)

Metriky neukazujÃ­ nic dobrÃ©ho - recall i precision lÃ©tÃ¡ tam a zpÃ¡tky, mAP50-95 je tragickÃ¡, validaÄnÃ­ loss funkce majÃ­ extrÃ©mnÃ­ hodnoty.

[![](/images/2023/2023-06-20-15-20-46.png){:class="img-fluid"}](/images/2023/2023-06-20-15-20-46.png)

KdyÅ¾ se podÃ­vÃ¡me znovu na fotku ÄlovÃ­Äka, model vidÃ­ vÅ¡ude plyÅ¡Ã¡ky.

[![](/images/2023/2023-06-20-15-49-08.png){:class="img-fluid"}](/images/2023/2023-06-20-15-49-08.png)

MÃ¡me tady jasnÃ½ overfit. DÄ›lat rozmÃ¡chlÃ© modely kdyÅ¾ nemÃ¡me poÅ™Ã¡dnÃ¡ data evidentnÄ› nedÃ¡vÃ¡ smysl.

## ZamÄenÃ© vrstvy
V pÅ™edchozÃ­m scÃ©nÃ¡Å™i jsme ovliÅˆovali vÅ¡echny vrstvy. Fine-tuning modelu se nÄ›kdy dÄ›lÃ¡ tak, Å¾e prvotnÃ­ vrstvy modelu zamkneme - nepÅ™ipustÃ­me jejich zmÄ›nu, jejich uÄenÃ­, a ladÃ­me aÅ¾ pozdÄ›jÅ¡Ã­ vrtvy, kterÃ© pÅ™edstavujÃ­ uÅ¾ reprezentace vyÅ¡Å¡Ã­ch vlastnostÃ­ (mÃ­sto hran tÅ™eba ouÅ¡ka). To mÅ¯Å¾e snÃ­Å¾it dobu uÄenÃ­ (zejmÃ©na pokud mÃ¡me relativnÄ› hodnÄ› novÃ½ch dat) a snÃ­Å¾it overfit. ExtrÃ©mnÃ­ podoba pak je, Å¾e vÅ¡echny vrstvy zpracovÃ¡nÃ­ obrazu zmrazÃ­me a pÅ™etrÃ©nujeme jen klasifikaÄnÃ­ vrstvy (computer vision obvykle funguje tak, Å¾e mÃ¡ pomÄ›rnÄ› dost konvoluÄnÃ­ch vrstev, tedy tÄ›ch co nejsou plnÄ›, ale mÃ­stnÄ› propojenÃ©, analyzujÃ­ souvisejÃ­cÃ­ oblasti obrazu a postupnÄ› extrahujÃ­ vyÅ¡Å¡Ã­ a vyÅ¡Å¡Ã­ vlastnosti - a nad nimi jsou plnÄ› propojenÃ© vrstvy klasifikaÄnÃ­, kterÃ© interpretujÃ­ vÃ½sledek zpracovÃ¡nÃ­ obrazu). Tomu se pak Å™Ã­kÃ¡ feature extraction. NechÃ¡me model zpracovÃ¡vat obrÃ¡zky beze zmÄ›ny, ale vÃ½slednÃ½ set features budeme jinak interpretovat.

YOLOv5 mÄ›lo zamykÃ¡nÃ­ pÅ™Ã­mo ve svÃ©m API, ale u v8 uÅ¾ to nenÃ­. ZdÃ¡ se, Å¾e dÅ¯vodem je, Å¾e rychlost trÃ©novÃ¡nÃ­ v8 to zas tak zÃ¡sadnÄ› neovlivÅˆuje, tak to tam nedali. NicmÃ©nÄ› lze to udÄ›lat pÅ™es callback, kdy se na zaÄÃ¡tku trÃ©novÃ¡nÃ­ model pÅ™edÃ¡ naÅ¡Ã­ funkci, kterÃ¡ probÄ›hne vrstvy a pÃ¡r prvnÃ­ch zmrazÃ­ (v Pytorch nastavÃ­ `requires_grad` na `False`).

```python
def freeze_layer(trainer):
    model = trainer.model
    num_freeze = 10
    print(f"Freezing {num_freeze} layers")
    freeze = [f'model.{x}.' for x in range(num_freeze)]  # layers to freeze 
    for k, v in model.named_parameters(): 
        v.requires_grad = True  # train all layers 
        if any(x in k for x in freeze): 
            print(f'freezing {k}') 
            v.requires_grad = False 
    print(f"{num_freeze} layers are freezed.")

# Uncomment to freeze layers
model.add_callback("on_train_start", freeze_layer)
```

VezmÄ›me si model velikost L. Ten jak jsme dÅ™Ã­ve vidÄ›li trpÄ›l na naÅ¡em extrÃ©mnÄ› malÃ©m vzorku dat masivnÃ­m pÅ™etrÃ©novÃ¡nÃ­m. Co kdyÅ¾ zamknu prvnÃ­ch 10 vrstev? ÄŒas trÃ©novÃ¡nÃ­ poÄÃ­tanÃ½ na 100 epoch klesl z 8 na 6 minut na mÃ© A100 v Azure, coÅ¾ nenÃ­ nÄ›jak velkÃ¡ Ãºspora, ale u vÄ›tÅ¡Ã­ho mnoÅ¾stvÃ­ dat, kde by celÃ© trÃ©novÃ¡nÃ­ bylo tÅ™eba o Å™Ã¡d vÄ›tÅ¡Ã­, uÅ¾ nÄ›jakÃ½ ten dolÃ¡rek uÅ¡etÅ™Ã­m. PodstatnÄ›jÅ¡Ã­ ale je, Å¾e zamÄenÃ­m iniciÃ¡lnÃ­ch vrstev bychom mÄ›li i snÃ­Å¾it schopnost modelu udÄ›lat rychlÃ½ overfit.

ObrÃ¡zek plyÅ¡Ã¡ku dopadl skuteÄnÄ› nadmÃ­ru dobÅ™e.

[![](/images/2023/2023-06-21-06-50-44.png){:class="img-fluid"}](/images/2023/2023-06-21-06-50-44.png)

V obrÃ¡zku bez plyÅ¡Ã¡kÅ¯ ale stÃ¡le vidÃ­me dost velkÃ½ overfit, nicmÃ©nÄ› srovnejte s pÅ™edchozÃ­m odstavcem - dramatickÃ© zlepÅ¡enÃ­.

[![](/images/2023/2023-06-21-06-50-54.png){:class="img-fluid"}](/images/2023/2023-06-21-06-50-54.png)

KdyÅ¾ koukneme na metriky, tak vypadajÃ­ daleko pÅ™Ã­ÄetnÄ›ji. Loss funkce pÅ™i trÃ©novÃ¡nÃ­ klesajÃ­, vybavovacÃ­ schopnost i pÅ™esnost rostou.

[![](/images/2023/2023-06-21-06-59-18.png){:class="img-fluid"}](/images/2023/2023-06-21-06-59-18.png)

A co kdyÅ¾ mu zamknu 30 vrstev? To uÅ¾ je evidentnÄ› moc (u YOLOv5 se doporuÄovalo zkouÅ¡et zamykat nÄ›co mezi 5 a 10 vrstvami). Situace je ale poÅ™Ã¡d lepÅ¡Ã­, neÅ¾ u ÃºplnÄ› pÅ¯vodnÃ­ho scÃ©nÃ¡Å™e velkÃ©ho modelu.

[![](/images/2023/2023-06-21-06-58-27.png){:class="img-fluid"}](/images/2023/2023-06-21-06-58-27.png)

[![](/images/2023/2023-06-21-06-58-47.png){:class="img-fluid"}](/images/2023/2023-06-21-06-58-47.png)

Metriky jsou opÄ›t zbÄ›silÃ© - hodnÄ› skÃ¡Äou, model se evidentnÄ› neuÄÃ­ moc dobÅ™e.

[![](/images/2023/2023-06-21-06-59-35.png){:class="img-fluid"}](/images/2023/2023-06-21-06-59-35.png)

ObecnÄ› vzato zdÃ¡ se, Å¾e kvalitativnÄ› je lepÅ¡Ã­ provÃ¡dÄ›t fine-tuning. Feature extraction mÅ¯Å¾e bÃ½t ale dobrÃ¡ volba tam, kde je novÃ½ch dat straÅ¡nÄ› moc a rozdÃ­l v nÃ¡kladech na zmÄ›nu modelu je zÃ¡sadnÃ­. TÅ™eba jako doÄasnÃ© opatÅ™enÃ­, neÅ¾ udÄ›lÃ¡te plnohodnotnÃ½ fine-tuning nebo dokonce svÅ¯j vlastnÃ­ model (a to je nÃ¡mÄ›t dalÅ¡Ã­ho dÃ­lu).



Dnes jsme si tedy vyzkouÅ¡eli fine-tuning modelu, transfer learning. VyuÅ¾ili jsme vÃ½sledky nÄ›koho jinÃ©ho, kdo utratil spoustu penÄ›z za bÄ›h GPU, a nad tÃ­m rychle vytrÃ©novali naÅ¡e plyÅ¡Ã¡ky. NicmÃ©nÄ› vÅ¡imnÄ›te si, Å¾e teÄ mÃ¡me model na plyÅ¡Ã¡ky a model na to ostatnÃ­ - ale ne dohromady. To nemusÃ­ vadit, spojÃ­me si to aplikaÄnÄ›, ale ne vÅ¾dy je to vÃ½sledek co chceme.

PÅ™Ã­Å¡tÄ› se podÃ­vÃ¡me na to, jak natrÃ©novat ÃºplnÄ› vlastnÃ­ model, jak dÄ›lat transfer learning z vlastnÃ­ho modelu na novÃ¡ data a srovnÃ¡me vÃ½poÄetnÃ­ nÃ¡roÄnost s  pÅ™etrÃ©novÃ¡nÃ­m se starÃ½mi i novÃ½mi daty.